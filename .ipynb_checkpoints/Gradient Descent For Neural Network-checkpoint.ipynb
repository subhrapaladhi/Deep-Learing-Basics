{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting if a person would buy life insurnace based on his age using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Insurance_Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['age','affordibility']]\n",
    "y = df.bought_insurance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age']/100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,),activation='sigmoid',kernel_initializer='ones',bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled,y_train,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef, intercept = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bias\n",
    "intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the log loss(Binary cross entropy)\n",
    "def log_loss(y_real, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    # convert the 0 to epsilon\n",
    "    y_predicted = [max(i,epsilon) for i in y_predicted]\n",
    "    # convert 1 to 1-epsilon\n",
    "    y_predicted = np.array([min(i,1-epsilon) for i in y_predicted])\n",
    "    logLoss = -np.mean(y_real*np.log(y_predicted)+(1-y_real)*np.log(1-y_predicted))\n",
    "    return logLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the sigmoid fucntion on a whole array\n",
    "def sigmoid_numpy(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNN:\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 1\n",
    "        self.bias = 0\n",
    "    \n",
    "    def fit(self, X, y, epochs, loss_threshold):\n",
    "        self.w1, self.w2, self.bias = self.gradient_descent(X['age'], X['affordibility'], y, epochs, loss_threshold)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        weighted_sum = self.w1*X_test['age'] + self.w2*X_test['affordibility'] + self.bias\n",
    "        return sigmoid_numpy(weighted_sum)\n",
    "    \n",
    "    def gradient_descent(self, age, affordibility, y_true, epochs, loss_threshold):\n",
    "        w1 = w2 = 1\n",
    "        bias = 0\n",
    "        rate = 0.5 # learning rate\n",
    "        n = len(age)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            weighted_sum = w1*age + w2*affordibility + bias\n",
    "            y_predicted = sigmoid_numpy(weighted_sum)\n",
    "            loss = log_loss(y_true,y_predicted)\n",
    "\n",
    "            #fiding the derivatives\n",
    "            w1_d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true))\n",
    "            w2_d = (1/n)*np.dot(np.transpose(affordibility),(y_predicted-y_true))\n",
    "            bias_d = np.mean(y_predicted-y_true)\n",
    "\n",
    "            # updating the weights and bias\n",
    "            w1 = w1 - rate*w1_d\n",
    "            w2 = w2 - rate*w2_d\n",
    "            bias = bias - rate*bias_d\n",
    "            \n",
    "            if i%25 == 0:\n",
    "                print(f'Epoch: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}')\n",
    "\n",
    "            if(loss<=loss_threshold):\n",
    "                print(f'Epoch: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}')\n",
    "                break\n",
    "        print(f'Epoch: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}')\n",
    "        return w1,w2,bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, w1: 0.9735870554090863, w2: 0.9276373851660089, bias: -0.11621401159689329, loss: 0.7533655791117272\n",
      "Epoch: 25, w1: 1.1626593722282215, w2: 0.6743131347272098, bias: -0.8354207861038951, loss: 0.6229659931083777\n",
      "Epoch: 50, w1: 1.5302272080895147, w2: 0.7467614156091524, bias: -1.0412437858276409, loss: 0.6082731052450916\n",
      "Epoch: 75, w1: 1.8835637469266067, w2: 0.7979939232650832, bias: -1.2219301317556364, loss: 0.5954089542992953\n",
      "Epoch: 100, w1: 2.2207626631778417, w2: 0.8354187456545137, bias: -1.3855501801817134, loss: 0.5840147278521037\n",
      "Epoch: 125, w1: 2.541543394768044, w2: 0.8643650451290783, bias: -1.5361180415319018, loss: 0.5738645001606684\n",
      "Epoch: 150, w1: 2.846163007780166, w2: 0.8880773551425616, bias: -1.67625053116322, loss: 0.5647925375477527\n",
      "Epoch: 175, w1: 3.135181465527246, w2: 0.9085300968765314, bias: -1.807704707270465, loss: 0.5566655711125256\n",
      "Epoch: 200, w1: 3.4093186848209664, w2: 0.9269229884226572, bias: -1.9317005092755386, loss: 0.549371253786572\n",
      "Epoch: 225, w1: 3.669366915272312, w2: 0.9439823998691189, bias: -2.0491180430229865, loss: 0.5428127825153725\n",
      "Epoch: 250, w1: 3.9161376879938476, w2: 0.9601454198704168, bias: -2.1606189563777356, loss: 0.5369059366082136\n",
      "Epoch: 275, w1: 4.150430414610725, w2: 0.9756725818808978, bias: -2.2667215821752484, loss: 0.5315771224264617\n",
      "Epoch: 300, w1: 4.373014517870396, w2: 0.9907170083761522, bias: -2.3678478030334182, loss: 0.5267618903237961\n",
      "Epoch: 325, w1: 4.584619974078992, w2: 1.0053668504301811, bias: -2.4643525534671116, loss: 0.5224037172943096\n",
      "Epoch: 350, w1: 4.7859330368969415, w2: 1.0196713283144705, bias: -2.556542618025121, loss: 0.5184529707083025\n",
      "Epoch: 375, w1: 4.977595106102031, w2: 1.0336566850889366, bias: -2.6446887988409227, loss: 0.5148660136518993\n",
      "Epoch: 375, w1: 4.977595106102031, w2: 1.0336566850889366, bias: -2.6446887988409227, loss: 0.5148660136518993\n",
      "Epoch: 375, w1: 4.977595106102031, w2: 1.0336566850889366, bias: -2.6446887988409227, loss: 0.5148660136518993\n"
     ]
    }
   ],
   "source": [
    "customModel = myNN()\n",
    "customModel.fit(X_train_scaled, y_train, epochs=500, loss_threshold = 0.515)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     0.806168\n",
       "25    0.745901\n",
       "8     0.813828\n",
       "21    0.205786\n",
       "0     0.373797\n",
       "12    0.214041\n",
       "17    0.781764\n",
       "22    0.593875\n",
       "11    0.445886\n",
       "13    0.231264\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customModel.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
